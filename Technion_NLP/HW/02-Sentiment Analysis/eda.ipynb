{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from config import DATA_PATH\n",
    "from preloading import load_datasets\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_datasets Start\n",
      "loading 40000 train records\n",
      "loading 10000 test records\n",
      "load_datasets Start\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = load_datasets(f\"{DATA_PATH}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review sentiment  target\n0  If you enjoy films like American Pie, Road Tri...  negative       0\n1  After having seen a lot of Greek movies I feel...  positive       1\n2  Seeing as Keifer Sutherland plays my favorite ...  positive       1\n3  My Take: A tired formula Christmas comedy. The...  negative       0\n4  It's been a long time since I last saw a movie...  negative       0\n5  Over the past century, there have been many ad...  positive       1\n6  Maybe television will be as brutal one day. Ma...  negative       0\n7  This film was not only one of John Ford's own ...  positive       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>If you enjoy films like American Pie, Road Tri...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>After having seen a lot of Greek movies I feel...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Seeing as Keifer Sutherland plays my favorite ...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My Take: A tired formula Christmas comedy. The...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It's been a long time since I last saw a movie...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Over the past century, there have been many ad...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Maybe television will be as brutal one day. Ma...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>This film was not only one of John Ford's own ...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['review', 'sentiment'], dtype='object')"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_df['target'] = pd.factorize(train_df['sentiment'], sort=True)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review sentiment  target\n0  If you enjoy films like American Pie, Road Tri...  negative       0\n1  After having seen a lot of Greek movies I feel...  positive       1\n2  Seeing as Keifer Sutherland plays my favorite ...  positive       1\n3  My Take: A tired formula Christmas comedy. The...  negative       0\n4  It's been a long time since I last saw a movie...  negative       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>If you enjoy films like American Pie, Road Tri...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>After having seen a lot of Greek movies I feel...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Seeing as Keifer Sutherland plays my favorite ...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My Take: A tired formula Christmas comedy. The...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It's been a long time since I last saw a movie...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review sentiment\n0  A lot of the comments seem to treat this film ...  positive\n1  A young man kills a young woman for no reason....  negative\n2  Four macho rough'n'tumble guys and three sexy ...  positive\n3  If it had not been for Christopher Guest's hil...  negative\n4  After a lively if predictable opening bank-hei...  negative",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A lot of the comments seem to treat this film ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A young man kills a young woman for no reason....</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Four macho rough'n'tumble guys and three sexy ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>If it had not been for Christopher Guest's hil...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>After a lively if predictable opening bank-hei...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "positive    20048\nnegative    19952\nName: sentiment, dtype: int64"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "negative    5048\npositive    4952\nName: sentiment, dtype: int64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['hello', ',', 'how', 'are', 'you', '?']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "tokenizer = get_tokenizer(\"basic_english\") ## We'll use tokenizer available from PyTorch\n",
    "tokenizer(\"Hello, How are you?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # url = {\n",
    "    #     '42B': 'http://nlp.stanford.edu/data/glove.42B.300d.zip',\n",
    "    #     '840B': 'http://nlp.stanford.edu/data/glove.840B.300d.zip',\n",
    "    #     'twitter.27B': 'http://nlp.stanford.edu/data/glove.twitter.27B.zip',\n",
    "    #     '6B': 'http://nlp.stanford.edu/data/glove.6B.zip',\n",
    "    # }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "global_vectors = GloVe(name='twitter.27B', dim=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6, 100])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = global_vectors.get_vecs_by_tokens(tokenizer(\"Hello, How are you?\"), lower_case_backup=True)\n",
    "embeddings.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 3.0055e-01,  8.0686e-01, -2.9994e-01, -2.8720e-01, -1.8295e-01,\n          1.0378e+00,  8.7783e-02,  1.5620e-01,  1.6044e-01, -2.1472e-02,\n         -3.0117e-01, -1.6142e-01, -3.9187e+00,  1.1904e-01,  9.7026e-02,\n         -2.3708e-01,  5.1175e-01, -1.7012e-01,  3.1123e-01, -6.5338e-01,\n          2.5613e-01,  9.6710e-02, -2.5963e-01, -2.4629e-01, -2.1014e-03,\n         -1.0390e+00, -1.1399e-01, -3.3197e-01,  2.1347e-01,  3.7158e-01,\n          2.1336e-01, -1.1778e-01, -9.3767e-02, -3.2307e-01,  1.8892e-01,\n          1.5611e-01,  8.0243e-02,  7.2999e-02, -6.2431e-02,  4.1545e-01,\n         -1.8762e+00, -7.8831e-02,  7.7317e-01, -1.2493e-01, -3.6049e-02,\n          1.3602e-01,  9.1399e-02, -3.2078e-01, -4.7738e-01,  2.5548e-01,\n         -2.8349e-01, -1.2392e-02,  9.2535e-02, -9.2562e-01,  2.4657e-01,\n          2.9753e-03, -4.1262e-02, -1.1225e+00,  1.0138e-01,  8.8375e-02,\n         -1.0234e-02, -1.3363e-01,  7.7226e-01, -4.4108e-01,  4.3879e-01,\n         -2.7009e-01, -1.7261e-01,  6.7119e-01,  2.1223e-01,  4.5418e-01,\n          6.0845e-02,  1.1389e-01,  3.2741e-01, -8.0893e-01,  9.7844e-01,\n         -2.0400e-01,  2.0409e-01,  2.8626e-01,  2.2076e-01, -1.2045e-01,\n          1.8047e+00, -3.4627e-02, -4.9862e-01,  3.7554e-01,  1.1020e+00,\n         -1.5276e-01,  4.5915e-01,  3.6702e-01,  2.1858e-01,  5.1044e-01,\n         -2.7338e-02, -2.2035e-01,  7.9190e-01,  9.3578e-01, -5.0691e-01,\n          3.0777e-01, -4.3588e-01,  4.2565e-01,  8.4077e-01, -6.7265e-01],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 5.5793e-01,  1.0748e-01, -5.7491e-01,  4.8770e-01, -3.7792e-01,\n         -3.6457e-02,  1.0581e+00,  5.9584e-02, -1.9582e-01, -4.1366e-01,\n          5.4969e-02,  1.0674e-01, -2.7076e+00, -5.0818e-01, -4.7456e-01,\n          3.2746e-01,  4.1643e-01, -5.3607e-01, -2.4822e-01, -6.3456e-01,\n         -7.5781e-02, -1.1904e+00, -7.2504e-01,  1.9499e-01,  2.9645e-02,\n         -9.8157e-01,  2.7081e-01,  3.2472e-01,  5.1154e-01, -8.6702e-01,\n         -3.6342e-01,  1.4098e-01, -4.4251e-01,  2.4804e-01,  1.4021e-01,\n         -4.2186e-02,  1.0408e-01,  2.3267e-01,  2.6663e-01,  4.0316e-01,\n         -9.1011e-01,  4.9339e-02,  1.4842e-01,  7.0496e-01, -1.3448e-02,\n          3.5591e-01, -2.3494e-01, -8.3828e-01,  6.9803e-03,  4.4702e-01,\n         -2.7031e-01,  3.2742e-03,  1.3265e-01, -6.8583e-01,  9.0147e-01,\n          6.0725e-01, -1.8490e-01,  8.6123e-02, -1.6930e-01, -4.8741e-01,\n          3.3445e-01, -1.0119e-01, -5.4273e-02, -3.5999e-01, -4.8967e-01,\n         -3.6699e-01, -9.1001e-01, -3.8762e-01,  1.4981e-01,  1.4092e-01,\n          6.0640e-01, -2.5070e-01,  1.5820e-01, -3.3841e-01, -2.5642e-02,\n          1.6793e-01, -4.5698e-02,  6.2762e-01,  3.0663e-01,  2.5571e-01,\n          1.5495e+00, -4.0935e-01,  3.4489e-01,  1.1414e-01,  1.1457e-01,\n         -3.1949e-01, -2.6473e-01,  2.9560e-01,  6.7942e-01, -1.9812e-01,\n          3.1416e-01, -3.7571e-01, -5.2265e-01,  4.2794e-02, -3.5241e-01,\n         -5.7055e-02,  2.7578e-01,  4.5650e-02,  2.7945e-01,  1.1518e-01]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_vectors.get_vecs_by_tokens([\"am\", \"Enoti\", \"hello\"], lower_case_backup=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "max_words = 25\n",
    "embed_len = 100\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    X, Y = list(zip(*batch))\n",
    "    X = [tokenizer(x) for x in X]\n",
    "    X = [tokens+[\"\"] * (max_words-len(tokens))  if len(tokens)<max_words else tokens[:max_words] for tokens in X]\n",
    "    X_tensor = torch.zeros(len(batch), max_words, embed_len)\n",
    "    for i, tokens in enumerate(X):\n",
    "        X_tensor[i] = global_vectors.get_vecs_by_tokens(tokens)\n",
    "    return X_tensor.reshape(len(batch), -1), torch.tensor(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pytorch Torchtext Tutorial 1: Custom Datasets and loading JSON/CSV/TSV files\n",
    "# https://www.youtube.com/watch?v=KRgq4VnCr7I\n",
    "# https://towardsdatascience.com/custom-datasets-in-pytorch-part-2-text-machine-translation-71c41a3e994e\n",
    "\n",
    "# How to build custom Datasets for Text in Pytorch\n",
    "# https://www.youtube.com/watch?v=9sHcLvVXsns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.functional import to_map_style_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Change TF IDF to glove"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        # Read data\n",
    "        self.data_df = pd.read_csv(file_path)\n",
    "        self.data_df['target'] = pd.factorize(self.data_df['sentiment'], sort=True)[0]\n",
    "\n",
    "        # # Split to sentences and labels\n",
    "        # self.sentences = data['review'].tolist()\n",
    "        # self.labels = data['sentiment'].tolist()\n",
    "        #\n",
    "        # # Enumerate labels\n",
    "        # self.label_to_idx = {tag: idx for idx, tag in enumerate(sorted(list(set(self.labels))))}\n",
    "        # self.idx_to_label = {idx: tag for tag, idx in self.label_to_idx.items()}\n",
    "        #\n",
    "        # # Tokenize sentences\n",
    "        # if tokenizer is not None:\n",
    "        #     self.tokenizer = tokenizer\n",
    "        #     self.tokenized_sen = self.tokenizer.transform(self.sentences)\n",
    "        # else:\n",
    "        #     self.tokenizer = TfidfVectorizer(lowercase=True, stop_words=None)\n",
    "        #     self.tokenized_sen = self.tokenizer.fit_transform(self.sentences)\n",
    "        #\n",
    "        # # Set vocab_size attribute\n",
    "        # self.vocab_size = len(self.tokenizer.vocabulary_)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        # Tensorize sentence\n",
    "        # tokenzied_sentence = self.tokenized_sen[item]\n",
    "        # tensor_tokenzied_sentence = torch.FloatTensor(tokenzied_sentence.toarray()).squeeze()\n",
    "        #\n",
    "        # # Get label idx\n",
    "        # label = self.labels[item]\n",
    "        # label = self.label_to_idx[label]\n",
    "        #\n",
    "        # # data = {\"input_vectors\": tensor_tokenzied_sentence, \"labels\": label}\n",
    "        # data = label, item\n",
    "        # print('get_item')\n",
    "        return self.data_df.iloc[item]['review'], self.data_df.iloc[item]['target'],\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "train_dataset = ClassificationDataset('./data/IMDB_train.csv')\n",
    "test_dataset = ClassificationDataset('./data/IMDB_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "(\"If you enjoy films like American Pie, Road Trip & Van Wilder; avoid this cinematic refuse at all costs. It is an unamusing, mean-spirited, insipid waste of resources that should never have been discussed aloud; much less actually recorded and sold to unsuspecting consumers. Easily the worst film I have seen in the past 18 months; mind-numbingly bad for the entire 86 minutes of it's runtime. Had it been much longer, I would not have been able to write this review without using profanity. Consider yourself warned!\",\n 0)"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, collate_fn=vectorize_batch)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=8, collate_fn=vectorize_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 0.1631,  0.7251,  0.0381,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.4531,  0.2241,  0.0599,  ..., -0.3358,  0.1888, -0.4079],\n         [ 0.3689,  0.4753, -0.0480,  ..., -0.5108,  0.4688,  0.3488],\n         ...,\n         [-0.1304,  0.2049,  0.4257,  ..., -0.4291,  1.0746, -0.3655],\n         [ 0.2932,  0.2109,  0.1146,  ..., -0.3128,  0.0414, -0.4936],\n         [ 0.1763,  0.3684,  0.3005,  ..., -0.0714, -0.6362,  0.8726]]),\n tensor([0, 1, 1, 0, 0, 1, 0, 1]))"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "target_classes = ['pos', 'neg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingClassifier, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(max_words*embed_len, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, len(target_classes)),\n",
    "        )\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        return self.seq(X_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "\n",
    "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
    "    with torch.no_grad():\n",
    "        Y_shuffled, Y_preds, losses = [],[],[]\n",
    "        for X, Y in val_loader:\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            Y_shuffled.append(Y)\n",
    "            Y_preds.append(preds.argmax(dim=-1))\n",
    "\n",
    "        Y_shuffled = torch.cat(Y_shuffled)\n",
    "        Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n",
    "\n",
    "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
    "    for i in range(1, epochs+1):\n",
    "        losses = []\n",
    "        for X, Y in tqdm(train_loader):\n",
    "            Y_preds = model(X)\n",
    "\n",
    "            loss = loss_fn(Y_preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if i%5==0:\n",
    "            print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "            CalcValLossAndAccuracy(model, loss_fn, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:36<00:00, 137.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "epochs = 1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "embed_classifier = EmbeddingClassifier()\n",
    "optimizer = Adam(embed_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "TrainModel(embed_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "def MakePredictions(model, loader):\n",
    "    Y_shuffled, Y_preds = [], []\n",
    "    for X, Y in loader:\n",
    "        preds = model(X)\n",
    "        Y_preds.append(preds)\n",
    "        Y_shuffled.append(Y)\n",
    "    gc.collect()\n",
    "    Y_preds, Y_shuffled = torch.cat(Y_preds), torch.cat(Y_shuffled)\n",
    "\n",
    "    return Y_shuffled.detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).detach().numpy()\n",
    "\n",
    "Y_actual, Y_preds = MakePredictions(embed_classifier, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbeddingClassifier(\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=2500, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(embed_classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}