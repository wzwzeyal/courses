{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zXIWIihjaJng",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from config import DATA_PATH\n",
    "# from preloading import load_datasets\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import nltk\n",
    "from torchtext.data import get_tokenizer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from nltk.corpus import stopwords\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "stop = stopwords.words('english')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def strip_text(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
    "    text = re.sub(r'https?:/\\/\\S+', ' ', text)\n",
    "    return text.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def review_clean_list(text):\n",
    "    word_list = tokenizer(text)\n",
    "    strip_words = [strip_text(word) for word in word_list]\n",
    "    str_list = list(filter(None, strip_words))\n",
    "    return str_list\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YE484-EKcA59",
    "outputId": "8d111a18-b33e-4c95-a6aa-dc09090e9a42",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dim=300\n",
    "global_vectors = GloVe(name='840B', dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q95FVInreACM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# max_words = 512\n",
    "embed_len = dim\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    X, Y = list(zip(*batch))\n",
    "    # X = [tokenizer(x) for x in X]\n",
    "    # X = [tokens+[\"\"] * (max_words-len(tokens))  if len(tokens)<max_words else tokens[:max_words] for tokens in X]\n",
    "    X_tensor_128_300 = torch.zeros(len(batch), embed_len)\n",
    "    for i, tokens in enumerate(X):\n",
    "        token_x_300 = global_vectors.get_vecs_by_tokens(tokens)\n",
    "        # print(f'token_x_???_300 shape: {token_x_300.shape}')\n",
    "        token_300 = token_x_300.mean(dim=0)\n",
    "        # print(f'token_300 shape: {token_300.shape}')\n",
    "        X_tensor_128_300[i] = token_300\n",
    "    Y_tensor = torch.tensor(Y)\n",
    "    # return X_tensor.reshape(len(batch), -1), Y_tensor.reshape(len(batch), -1)\n",
    "    # return X_tensor.reshape(len(batch), -1), Y_tensor\n",
    "    return X_tensor_128_300.reshape(len(batch), -1), Y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vzuzlQmybfdt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RSvQN8sceP2B",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_mean_token(wordlist):\n",
    "    token_x_300 = global_vectors.get_vecs_by_tokens(wordlist)\n",
    "    return token_x_300.mean(dim=0)\n",
    "\n",
    "\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "\n",
    "        print(f'processing of {file_path} started ...')\n",
    "        # Read data\n",
    "        self.data_df = pd.read_csv(file_path)\n",
    "\n",
    "        print(\"tokenizing ...\")\n",
    "        self.data_df['tokens'] =  self.data_df.progress_apply(lambda x: tokenizer(x[\"review\"]), axis=1)\n",
    "\n",
    "        print(\"calculating mean tokens ...\")\n",
    "        self.data_df['mean_token'] =  self.data_df.progress_apply(lambda x: calc_mean_token(x[\"tokens\"]), axis=1)\n",
    "\n",
    "        # pat = r'\\b(?:{})\\b'.format('|'.join(stop))\n",
    "        # # remove stop stop words\n",
    "        # print('removing stopwords ...')\n",
    "        # self.data_df['clean_review'] = self.data_df['review'].str.lower().replace(pat, '', regex=True)\n",
    "        # self.data_df['clean_review'] = self.data_df['clean_review'].str.replace(r'\\s+', ' ', regex=True)\n",
    "        #\n",
    "        # print('cleaning words ...')\n",
    "        # self.data_df['clean_review'] =  self.data_df.progress_apply(lambda x: review_clean_list(x['clean_review']), axis=1)\n",
    "        #\n",
    "        # print('calculating mean clean tokens ...')\n",
    "        # self.data_df['mean_token'] =  self.data_df.progress_apply(lambda x: calc_mean_token(x['clean_review']), axis=1)\n",
    "\n",
    "        print('converting sentiment to number ...')\n",
    "        self.data_df['target'] = pd.factorize(self.data_df['sentiment'], sort=True)[0]\n",
    "\n",
    "        print(f'processing of {file_path} finished !')\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {'mean_token': self.data_df.iloc[item]['mean_token'], 'target': self.data_df.iloc[item]['target']}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qHqrdIdNbef7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing of ./data/IMDB_train.csv started ...\n",
      "tokenizing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:04<00:00, 9232.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating mean tokens ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:22<00:00, 1760.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting sentiment to number ...\n",
      "processing of ./data/IMDB_train.csv finished !\n",
      "processing of ./data/IMDB_test.csv started ...\n",
      "tokenizing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 9959.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating mean tokens ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:05<00:00, 1851.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting sentiment to number ...\n",
      "processing of ./data/IMDB_test.csv finished !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ClassificationDataset(f'{DATA_PATH}/IMDB_train.csv', )\n",
    "test_dataset = ClassificationDataset(f'{DATA_PATH}/IMDB_test.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zP7JqXSfbaO8",
    "outputId": "9ce7851b-e750-47a5-b993-679ec8677e84",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean_token': tensor([-7.9182e-02,  1.6575e-01, -7.4260e-02, -9.8066e-02,  4.1668e-02,\n          6.3572e-02,  1.4033e-02, -1.2692e-01, -4.5773e-02,  2.1155e+00,\n         -1.4825e-01,  8.8027e-02,  8.2067e-02, -5.3264e-02, -1.3754e-01,\n         -9.5012e-02, -4.2865e-02,  9.5066e-01, -1.9094e-01, -2.4616e-02,\n         -1.3271e-03, -3.8259e-02,  7.3301e-03, -3.1398e-02, -2.3603e-02,\n          5.2116e-02, -6.6549e-02, -8.2620e-02,  7.0907e-02, -7.0348e-02,\n         -3.0290e-02,  2.0863e-02, -7.9536e-02,  8.0419e-02,  9.9465e-03,\n         -7.1210e-02,  3.5911e-03,  8.3683e-02, -5.1194e-02,  2.3098e-02,\n         -1.6146e-02,  3.9066e-02,  4.0759e-02,  1.8458e-03, -9.8923e-03,\n          4.8018e-02, -1.2642e-01,  1.5840e-02,  4.3178e-02, -1.5053e-03,\n         -7.4081e-02, -2.7364e-02, -5.6831e-03, -3.4428e-02,  7.8554e-02,\n          2.7589e-02, -7.5855e-03, -1.7494e-01,  3.7293e-02, -4.9840e-02,\n         -6.6120e-03, -5.9214e-02, -5.8622e-02,  2.1997e-01,  6.6509e-02,\n         -5.5419e-02,  5.5472e-03,  3.5946e-02,  3.1729e-02,  7.6902e-02,\n          1.4385e-01,  3.2092e-02,  1.8734e-01, -3.4405e-02,  1.0191e-01,\n          1.5333e-02,  6.7153e-02, -1.7138e-02, -3.3065e-02,  2.4321e-01,\n          3.1229e-02,  3.0660e-02, -1.3779e-01, -3.3729e-02,  2.2117e-03,\n         -2.6094e-01,  2.6215e-02, -1.7353e-01,  2.4619e-01,  2.3771e-02,\n         -1.0909e-01, -1.0751e-02, -2.8562e-02,  1.0081e-01,  1.0685e-01,\n          1.0469e-02,  5.8336e-03,  8.1651e-03, -3.2068e-02, -2.5878e-02,\n          2.3875e-02, -8.9412e-03, -1.0039e-01, -4.8228e-02,  1.0817e-01,\n         -7.1605e-01,  9.7667e-02,  8.6432e-03,  2.1511e-02, -3.5217e-02,\n          4.5851e-02, -1.4843e-01,  1.0985e-01, -1.3221e-01, -5.9330e-02,\n         -7.3795e-02, -9.3666e-03,  3.8772e-03, -3.7458e-02, -3.3236e-02,\n          7.4583e-02, -3.2944e-02, -2.1874e-02, -8.1191e-02, -6.4136e-03,\n          6.7994e-02, -2.0024e-02, -9.8401e-02, -2.2664e-02, -1.5766e-02,\n          2.6800e-02, -3.5514e-02, -6.4278e-02,  3.8207e-02,  4.6046e-02,\n          3.1312e-02, -5.9649e-02,  3.1526e-03,  1.5266e-03, -2.7329e-02,\n         -1.1919e+00,  9.7770e-02,  1.2415e-01,  2.4771e-03,  1.1915e-02,\n         -1.0963e-01, -1.2692e-01, -2.4789e-02,  7.5138e-02, -3.8106e-02,\n          4.2463e-02,  5.8391e-02,  8.9109e-02, -1.5510e-02, -5.0654e-02,\n         -8.3530e-02, -8.1426e-02, -1.7866e-02,  1.9771e-04, -6.7602e-02,\n         -5.5881e-02, -4.4200e-03,  5.1480e-03, -1.8368e-02, -1.2825e-01,\n         -7.9697e-02,  7.0306e-02, -9.4270e-02,  1.2965e-01, -3.7145e-02,\n          1.2406e-02, -5.2973e-02,  6.3760e-02, -9.0600e-02, -5.7107e-02,\n          3.6963e-02,  1.2494e-02, -2.9242e-02,  1.6867e-02, -6.4527e-02,\n         -8.7052e-03, -4.4037e-02, -1.2913e-01, -1.3480e-02, -2.8790e-02,\n         -4.8481e-02, -4.4641e-02, -1.7799e-03,  7.2672e-02,  8.1502e-02,\n          2.7535e-02,  5.0852e-02, -4.9061e-02,  1.0239e-01,  1.4675e-02,\n          1.4858e-02, -2.1981e-02, -8.1433e-02, -2.1608e-02,  1.4679e-01,\n          4.1026e-02, -6.3405e-02, -8.4884e-02, -1.0712e-02,  1.3235e-01,\n          4.4131e-02,  2.6113e-02,  7.4659e-03,  1.0912e-01,  4.4085e-02,\n          7.1345e-03, -3.3439e-02, -1.5901e-02, -1.5363e-01,  5.7674e-02,\n          1.1146e-01,  1.7006e-02,  4.2359e-02, -1.6724e-01,  6.0008e-03,\n          2.3319e-02,  1.2004e-02, -7.6336e-02, -3.3965e-03, -1.5382e-02,\n         -5.4263e-02, -4.0518e-02,  3.9221e-02, -4.9764e-02, -4.2375e-02,\n         -8.1845e-02,  2.2317e-02,  1.3712e-01,  9.6818e-02, -3.5265e-03,\n         -5.2620e-02,  3.3885e-02, -9.8270e-02, -1.0434e-01,  4.1485e-02,\n          7.8326e-02,  2.1157e-03,  3.4105e-02,  7.8609e-02,  9.6128e-02,\n         -1.0297e-01, -4.7211e-02, -3.5776e-02, -1.4254e-01,  1.3618e-01,\n         -9.8529e-03, -7.1876e-02,  4.2765e-03, -3.7819e-03,  3.7476e-02,\n          2.1667e-01,  8.3968e-02, -5.0181e-02, -2.4031e-02,  4.2479e-02,\n          1.3081e-01,  1.2424e-01,  7.4464e-03,  9.7558e-02,  1.0970e-01,\n         -4.0673e-02,  4.1294e-02,  6.2050e-02,  3.4223e-01,  3.0531e-02,\n          5.6066e-02, -7.2484e-02, -4.4716e-02, -1.7363e-01, -4.3655e-02,\n          2.5485e-02,  3.5887e-03,  6.3727e-02, -2.7087e-02,  1.6161e-01,\n          1.8277e-01,  4.4852e-02,  9.2249e-02, -4.9826e-02, -4.1301e-02,\n         -5.3804e-02,  1.2246e-01, -1.2744e-01,  1.1370e-01, -1.1931e-02,\n         -2.0443e-01,  6.1613e-02, -5.6354e-02, -1.8546e-02,  9.2691e-02,\n         -8.3373e-04, -9.0824e-02, -7.7895e-02,  3.6019e-03,  6.6390e-02]),\n 'target': 0}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "f2eRCXK3bu9W",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iy0Oh68FbxSC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)# , collate_fn=vectorize_batch)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) #, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRLFxas3b0Gt",
    "outputId": "aa8c2761-dea8-4b02-c1ff-1ebd6ba88eff",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean_token': tensor([[-0.0883,  0.1696, -0.2146,  ..., -0.1740,  0.0272,  0.0731],\n         [-0.0601,  0.1834, -0.1424,  ..., -0.0613,  0.0010,  0.0875],\n         [-0.0335,  0.0920, -0.1551,  ..., -0.0457,  0.0147,  0.0113],\n         ...,\n         [-0.0007,  0.1599, -0.1589,  ..., -0.0760,  0.0237,  0.1393],\n         [-0.0241,  0.1625, -0.1196,  ..., -0.0459,  0.0138,  0.0576],\n         [ 0.0007,  0.0782, -0.0833,  ..., -0.0345, -0.0435,  0.0669]]),\n 'target': tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n         0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n         0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n         0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n         0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n         1, 1, 0, 1, 1, 1, 1, 1])}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_item_dict = next(iter(train_loader))\n",
    "loader_item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([128, 300])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_item_dict['mean_token'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "a11o3BaKb2W4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1zlFnzwKb6eG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(EmbeddingClassifier, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(300, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 2),\n",
    "            # nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        hidden_128_1 =  self.seq(X_batch)\n",
    "        return hidden_128_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5sswLvKReiID",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Epoch(oModel, oDataDL, Loss, Metric, oOptim=None, oScheduler=None, bTrain=True):\n",
    "\n",
    "    epochLoss   = 0\n",
    "    epochMetric = 0\n",
    "    count       = 0\n",
    "    nIter       = len(oDataDL)\n",
    "    vLR         = np.full(nIter, np.nan)\n",
    "    DEVICE      = next(oModel.parameters()).device #-- CPU\\GPU\n",
    "\n",
    "\n",
    "    oModel.train(bTrain) #-- train or test\n",
    "\n",
    "    #-- Iterate over the mini-batches:\n",
    "    for ii, loader_item_dict in enumerate(oDataDL):\n",
    "        #-- Move to device (CPU\\GPU):\n",
    "        X = loader_item_dict['mean_token'].to(DEVICE)\n",
    "        Y = loader_item_dict['target'].to(DEVICE)\n",
    "\n",
    "        #-- Forward:\n",
    "        if bTrain == True:\n",
    "            \n",
    "            #-- Store computational graph:\n",
    "            mOut = oModel(X)\n",
    "\n",
    "            loss = Loss  (mOut,      Y)\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                #-- Do not store computational graph:\n",
    "                mOut = oModel(X)\n",
    "                loss = Loss  (mOut,      Y)\n",
    "\n",
    "        #-- Backward:\n",
    "        if bTrain == True:\n",
    "\n",
    "            oOptim.zero_grad() #-- set gradients to zeros\n",
    "            loss.backward()    #-- backward\n",
    "            oOptim.step()      #-- update parameters\n",
    "            if oScheduler is not None:\n",
    "                vLR[ii] = oScheduler.get_last_lr()[0]\n",
    "                oScheduler.step() #-- update learning rate\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            Nb           = X.shape[0]\n",
    "            count       += Nb\n",
    "            epochLoss   += Nb * loss.item()\n",
    "            epochMetric += Nb * Metric(mOut, Y)\n",
    "        print(f'\\r{\"Train\" if bTrain else \"Val\"} - Iteration: {ii:3d} ({nIter}): loss = {loss:2.6f}', end='')\n",
    "\n",
    "    print('', end='\\r')\n",
    "    epochLoss   /= count\n",
    "    epochMetric /= count\n",
    "\n",
    "    return epochLoss, epochMetric, vLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Iteration: 112 (313): loss = 0.684264"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [24]\u001B[0m, in \u001B[0;36m<cell line: 16>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     14\u001B[0m oOptim     \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdamW(oModel\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m, betas\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.9\u001B[39m, \u001B[38;5;241m0.99\u001B[39m), weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-2\u001B[39m)\n\u001B[1;32m     15\u001B[0m oScheduler \u001B[38;5;241m=\u001B[39m OneCycleLR (oOptim, max_lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m, total_steps\u001B[38;5;241m=\u001B[39mnIter)\n\u001B[0;32m---> 16\u001B[0m lHistory   \u001B[38;5;241m=\u001B[39m \u001B[43mTrainModel\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43moModel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLoss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMetric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnEpochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moOptim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moScheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEpoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEpoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msModelName\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mEmbeddingCLS\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/courses/Technion_NLP/HW/02/DeepLearningFramework/Training.py:75\u001B[0m, in \u001B[0;36mTrainModel\u001B[0;34m(oModel, oTrainData, oValData, Loss, Metric, nEpochs, oOptim, oScheduler, Epoch, sModelName)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(nEpochs):\n\u001B[1;32m     74\u001B[0m     startTime                    \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 75\u001B[0m     trainLoss, trainMetric, vLRi \u001B[38;5;241m=\u001B[39m \u001B[43mEpoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43moModel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moTrainData\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLoss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMetric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moOptim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moScheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbTrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#-- train\u001B[39;00m\n\u001B[1;32m     76\u001B[0m     valLoss,   valMetric,   _    \u001B[38;5;241m=\u001B[39m Epoch(oModel, oValData,   Loss, Metric,                     bTrain\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;66;03m#-- validate\u001B[39;00m\n\u001B[1;32m     77\u001B[0m     epochTime                    \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m startTime\n",
      "Input \u001B[0;32mIn [23]\u001B[0m, in \u001B[0;36mEpoch\u001B[0;34m(oModel, oDataDL, Loss, Metric, oOptim, oScheduler, bTrain)\u001B[0m\n\u001B[1;32m     11\u001B[0m oModel\u001B[38;5;241m.\u001B[39mtrain(bTrain) \u001B[38;5;66;03m#-- train or test\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m#-- Iterate over the mini-batches:\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ii, loader_item_dict \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(oDataDL):\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;66;03m#-- Move to device (CPU\\GPU):\u001B[39;00m\n\u001B[1;32m     16\u001B[0m     X \u001B[38;5;241m=\u001B[39m loader_item_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_token\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[1;32m     17\u001B[0m     Y \u001B[38;5;241m=\u001B[39m loader_item_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(DEVICE)\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[0;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    569\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 570\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    572\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36mClassificationDataset.__getitem__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, item):\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_token\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmean_token\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_df\u001B[38;5;241m.\u001B[39miloc[item][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/pandas/core/series.py:958\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    955\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[0;32m--> 958\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_hashable(key):\n\u001B[1;32m    961\u001B[0m     \u001B[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001B[39;00m\n\u001B[1;32m    962\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    963\u001B[0m         \u001B[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001B[39;00m\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/pandas/core/series.py:1069\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[0;34m(self, label, takeable)\u001B[0m\n\u001B[1;32m   1066\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[1;32m   1068\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[0;32m-> 1069\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39m_get_values_for_loc(\u001B[38;5;28mself\u001B[39m, loc, label)\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3619\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3614\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tolerance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3615\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   3616\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtolerance argument only valid if using pad, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3617\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackfill or nearest lookups\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3618\u001B[0m     )\n\u001B[0;32m-> 3619\u001B[0m casted_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_cast_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:6289\u001B[0m, in \u001B[0;36mIndex._maybe_cast_indexer\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   6284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_maybe_cast_indexer\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   6285\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   6286\u001B[0m \u001B[38;5;124;03m    If we have a float key and are not a floating index, then try to cast\u001B[39;00m\n\u001B[1;32m   6287\u001B[0m \u001B[38;5;124;03m    to an int if equivalent.\u001B[39;00m\n\u001B[1;32m   6288\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 6289\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   6290\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m com\u001B[38;5;241m.\u001B[39mcast_scalar_indexer(key)\n\u001B[1;32m   6291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m key\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:2386\u001B[0m, in \u001B[0;36mIndex.is_floating\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2344\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[1;32m   2345\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_floating\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m   2346\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2347\u001B[0m \u001B[38;5;124;03m    Check if the Index is a floating type.\u001B[39;00m\n\u001B[1;32m   2348\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2384\u001B[0m \u001B[38;5;124;03m    False\u001B[39;00m\n\u001B[1;32m   2385\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minferred_type\u001B[49m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloating\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmixed-integer-float\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minteger-na\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "nEpochs    = 20\n",
    "nIter      = nEpochs * len(train_loader)\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler       import OneCycleLR\n",
    "from DeepLearningFramework.Training import TrainModel\n",
    "from DeepLearningFramework.Metric   import Accuracy\n",
    "\n",
    "Loss   = nn.CrossEntropyLoss()\n",
    "Metric = Accuracy           ()\n",
    "\n",
    "DEVICE = torch.device       (\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "oModel     = EmbeddingClassifier  ().to(DEVICE, )\n",
    "oOptim     = optim.AdamW(oModel.parameters(), lr=0.001, betas=(0.9, 0.99), weight_decay=1e-2)\n",
    "oScheduler = OneCycleLR (oOptim, max_lr=0.001, total_steps=nIter)\n",
    "lHistory   = TrainModel (oModel, train_loader, test_loader, Loss, Metric, nEpochs, oOptim, oScheduler, Epoch=Epoch, sModelName='EmbeddingCLS')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lHistory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [25]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mDeepLearningFramework\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mAuxiliary\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PlotHistory\n\u001B[0;32m----> 3\u001B[0m PlotHistory(\u001B[43mlHistory\u001B[49m)\n\u001B[1;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow   ()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'lHistory' is not defined"
     ]
    }
   ],
   "source": [
    "from DeepLearningFramework.Auxiliary import PlotHistory\n",
    "\n",
    "PlotHistory(lHistory)\n",
    "plt.show   ()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3 ,4 , 5], dtype=float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "EmbeddingClassifier(\n  (seq): Sequential(\n    (0): Linear(in_features=300, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.2, inplace=False)\n    (3): Linear(in_features=512, out_features=64, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.2, inplace=False)\n    (6): Linear(in_features=64, out_features=2, bias=True)\n  )\n)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not dict",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m yhat \u001B[38;5;241m=\u001B[39m \u001B[43moModel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36mEmbeddingClassifier.forward\u001B[0;34m(self, X_batch)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, X_batch):\n\u001B[0;32m---> 21\u001B[0m     hidden_128_1 \u001B[38;5;241m=\u001B[39m  \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hidden_128_1\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 141\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/git/courses/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: linear(): argument 'input' (position 1) must be Tensor, not dict"
     ]
    }
   ],
   "source": [
    "yhat = oModel(next(iter(train_loader)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "loader_item_dict = next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean_token': tensor([[-0.0144,  0.1352, -0.1262,  ..., -0.0504,  0.0049,  0.0964],\n         [-0.0564,  0.1962, -0.1782,  ..., -0.0753,  0.0434,  0.0843],\n         [-0.0324,  0.1470, -0.1257,  ..., -0.0504, -0.0274, -0.0031],\n         ...,\n         [-0.0187,  0.2013, -0.1342,  ..., -0.0460,  0.0130,  0.0574],\n         [-0.0256,  0.1483, -0.1270,  ..., -0.0360, -0.0007,  0.0944],\n         [-0.0246,  0.0995, -0.0550,  ..., -0.1076,  0.0123,  0.0604]]),\n 'target': tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n         0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n         0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n         0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n         0, 0, 0, 0, 1, 1, 0, 0])}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_item_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "Y = oModel(loader_item_dict['mean_token'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "'rnn_torchviz.png'"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(Y, params=dict(list(oModel.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}